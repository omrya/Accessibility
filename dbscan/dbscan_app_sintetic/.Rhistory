GTFSagency$agency_nameENG[GTFSagency$agency_id == 4] <- "Egged_Taavura"
GTFSagency$agency_nameENG[GTFSagency$agency_id == 5] <- "Dan"
GTFSagency$agency_nameENG[GTFSagency$agency_id == 6] <- "Nazareth-unbs"
GTFSagency$agency_nameENG[GTFSagency$agency_id == 7] <- "NTT"
GTFSagency$agency_nameENG[GTFSagency$agency_id == 8] <- "GB-Tours"
GTFSagency$agency_nameENG[GTFSagency$agency_id == 10] <- "Mo'atza Ezorit Eilot"
GTFSagency$agency_nameENG[GTFSagency$agency_id == 14] <- "Netiv Expres"
GTFSagency$agency_nameENG[GTFSagency$agency_id == 15] <- "Metropoline"
GTFSagency$agency_nameENG[GTFSagency$agency_id == 16] <- "Superbus"
GTFSagency$agency_nameENG[GTFSagency$agency_id == 18] <- "Kavim"
GTFSagency$agency_nameENG[GTFSagency$agency_id == 19] <- "Metrodan"
GTFSagency$agency_nameENG[GTFSagency$agency_id == 20] <- "Karmelit"
GTFSagency$agency_nameENG[GTFSagency$agency_id == 21] <- "CityPass"
GTFSagency$agency_nameENG[GTFSagency$agency_id == 23] <- "Galim"
GTFSagency$agency_nameENG[GTFSagency$agency_id == 24] <- "Mo'atza Ezorit Golan"
GTFSagency$agency_nameENG[GTFSagency$agency_id == 25] <- "Afikim"
GTFSagency$agency_nameENG[GTFSagency$agency_id == 30] <- "Dan Tzafon"
GTFSagency$agency_nameENG[GTFSagency$agency_id == 31] <- "Dan BaDarom"
GTFSagency$agency_nameENG[GTFSagency$agency_id == 32] <- "Dan Be'er Sheva"
GTFSagency$agency_nameENG[GTFSagency$agency_id == 42] <- "Jerusalem-Ramllah Ihud"
GTFSagency$agency_nameENG[GTFSagency$agency_id == 44] <- "Jerusalem-AbuTur-Anta Ihud"
GTFSagency$agency_nameENG[GTFSagency$agency_id == 45] <- "Jerusalem-Alawast Ihud"
GTFSagency$agency_nameENG[GTFSagency$agency_id == 47] <- "Jerusalem-Har Hazeitim"
GTFSagency$agency_nameENG[GTFSagency$agency_id == 49] <- "Jerusalem-Issawia'a-Shuaafat Ihud"
GTFSagency$agency_nameENG[GTFSagency$agency_id == 50] <- "Jerusalem Darom Ihud"
GTFSagency$agency_nameENG[GTFSagency$agency_id == 51] <- "Jerusalem Tzur Baer Ihud"
}
#########
# create second key to subset the SIRI dataframe
# requires the SIRIdf to be after all other stages
SIRIKeepClosestStop <- function(SIRIdf){
a <- SIRIdf[order(SIRIdf$OriginAimedDepartureTime ,SIRIdf$stop_code, SIRIdf$distance),]
a$key2 <- paste(a$OriginAimedDepartureTime," ", a$stop_code)
a$key3 <- paste(a$OriginAimedDepartureTime," ", a$stop_id)
b <- a[!duplicated(a$key2),]
b
}
##########################
# subset GTFSstop_times to save on memory while using ot to compare to SIRI
substoptimes <- function(SIRIdf, GTFSstop_times = GTFSstop_times,GTFSroutes = GTFSroutes){
t <- GTFStrips[GTFStrips$route_id %in% SIRIdf$LineRef,]
cal <- GTFScalendar[GTFScalendar$service_id %in% t$service_id,]
week <- c("Sunday","Monday","Tuesday","Wednesday", "Thursday","Friday", "Saturday" )
colnames(cal)[2:8] <- week
cal[,9:10] <- sapply(cal[,9:10], as.character)
cal[,9] <- as.Date(cal[,9], format = "%Y%m%d")
cal[,10] <- as.Date(cal[,10], format = "%Y%m%d")
cal <- cal[cal$start_date <= as.Date(SIRIdf$RecordedAtTime[1])& as.Date(SIRIdf$RecordedAtTime[1]) <= cal$end_date,]
if(cal$start_date[1] <= as.Date(SIRIdf$RecordedAtTime[1]) & as.Date(SIRIdf$RecordedAtTime[1]) <= cal$end_date[1] & NROW(cal) >= 1){
c1 <- cal[,weekdays(SIRIdf$RecordedAtTime[1]) == colnames(cal)[2:8]]
if(class(c1) == "data.frame"){
t1 <- t[t$service_id %in% c1$service_id,]
st <- GTFSstop_times[GTFSstop_times$trip_id %in% t1$trip_id,]
st
}else{
c2 <- cal[c1 == 1,]
t1 <- t[t$service_id %in% c2$service_id,]
st <- GTFSstop_times[GTFSstop_times$trip_id %in% t1$trip_id,]
st
}
}
else{
print("SIRI does not match GTFS dates or day of week")
}
}
###########################
# needed for comparison between SIRI and stop times
organizeStopTimes <- function(Stimes = StimesforSIRI, SIRIdf3 = SIRIdf3){
s2 <- Stimes
x <- unique(s2$trip_id)
y <- s2$arrival_time[s2$stop_sequence == 1]
xx <- as.data.frame(table(s2$trip_id))
xx$Var2 <- y
depart_firststr <- rep(xx$Var2,xx$Freq)
if(length(depart_firststr) > 0){
s3 <- cbind(s2, depart_firststr)
s3$depart_firststr <- as.character(s3$depart_firststr)
s3$depart_first <- StopTimes2POSIXct(s3$depart_firststr,SIRIdf3)
s3$key <- paste(s3$depart_first," ", s3$stop_id)
s3$arrival_time <- StopTimes2POSIXct(s3$arrival_time,SIRIdf3)
s3$departure_time <- StopTimes2POSIXct(s3$departure_time,SIRIdf3)
s3 <- s3[!is.na(s3$arrival_time),]
s3
}else{
print('failed to subset stop times')
}
}
###########
# process the stop times df in order to use the times in it
#  warning, reqires 64 bit machine and 64 bit version of R.
# not recommended for use on the full df of GTFSstop_times
StopTimes2POSIXct <- function(column, SIRIref){
d <- column
time <- as.character(d)
date <- rep_len(as.character(as.Date(as.POSIXct(SIRIref$RecordedAtTime[1]))),length(time))
X <- paste(as.character(date)," ", as.character(time))
Y <- as.POSIXct(strptime(X,format = "%Y-%m-%d %H:%M:%S"))
Y
}
###############
# version of StopTimes2POSIXct for use in 32bit machines
# still might not work on entire GTFSstop_times
lowmemST2POSIX <- function(column, SIRIref){
s1 <- column
s2 <- as.Date(as.POSIXct(SIRIref$RecordedAtTime[1:length(column)]))
s2 <- as.character(s2)
s2 <- rep(s2[1],len = length(s1))
s3 <- s2[1:(length(s2)/2+1)]
s4 <- s2[length(s3):length(s2)]
s5 <- s1[1:(length(s1)/2+1)]
s6 <- s1[(length(s1)/2+1):length(s1)]
a1 <- paste0(s3, " ", s5)
a2 <- paste0(s4, " ", s6)
a3 <- (rbind(a1,a2))
a3 <- a3[1:(length(a3)-1)]
Y <- as.POSIXct(strptime(a3,format = "%Y-%m-%d %H:%M:%S"))
column <- Y
column <- column[-length(column)]
}
###############
# adding a trip number for the day
# will be used later for indexing
addtripnum <- function(ans2){
tripnum <- 1
tripnumvec <- vector()
ans2 <- ans2[order(ans2$OriginAimedDepartureTime,ans2$stop_sequence),]
ans2 <- ans2[!is.na(ans2$OriginAimedDepartureTime),]
for(ora in unique(ans2$OriginAimedDepartureTime[!is.na(ans2$OriginAimedDepartureTime)])){
if(length(ans2$OriginAimedDepartureTime[ans2$OriginAimedDepartureTime[!is.na(ans2$OriginAimedDepartureTime)] == ora]) > 0 ){
tripnumvec <-c(tripnumvec, rep_len(tripnum,length.out = length(ans2$OriginAimedDepartureTime[ans2$OriginAimedDepartureTime[!is.na(ans2$OriginAimedDepartureTime)] == ora]))  )
tripnum <- tripnum+1
}else{
tripnum <- tripnum+1
}
}
tripnumvec <- tripnumvec
ans2 <- cbind(ans2,tripnumvec)
}
loadcsv_multi <- function(directory){
directory <- choose.dir()
setwd(directory)
temp = list.files(pattern="*.csv")
list2env(
lapply(setNames(temp, make.names(paste0(gsub("*.csv$", "", temp)))),
read.csv,stringsAsFactors = FALSE, header = TRUE, quote = ""), envir = .GlobalEnv)
}
is.outlier <- function(spSIRI, trip){
siridfch <- gConvexHull(spSIRI[spSIRI@data$trip_id == trip,])
if(!is.null(siridfch)){
cent1 <- gCentroid(siridfch)
centbuffer <- gBuffer(cent1, width = 75)
outlier <- gWithin(spSIRI, centbuffer)
return(outlier)
}else{
print(paste('failed trip: ', trip))
}
}
loadGTFS()
trips <- GTFStrips[GTFStrips$route_id %in% routes$route_id,]
write.table(trips,"C:\\Analysis\\GIS\\gtfs_data\\israel-public-transportation_12072017_BSOnly\\trips.txt", sep = ",", row.names = FALSE)
shapes <- GTFSshapes[GTFSshapes$shape_id %in% trips$shape_id,]
write.table(shapes,"C:\\Analysis\\GIS\\gtfs_data\\israel-public-transportation_12072017_BSOnly\\shapes.txt", sep = ",", row.names = FALSE)
#All
stop_times <- GTFSstop_times[GTFSstop_times$trip_id %in% trips$trip_id,]
write.table(stop_times,"C:\\Analysis\\GIS\\gtfs_data\\israel-public-transportation_12072017_BSOnly\\stop_times.txt", sep = ",", row.names = FALSE)
stops <- GTFSstops[GTFSstops$stop_id %in% stop_times$stop_id,]
write.table(stops,"C:\\Analysis\\GIS\\gtfs_data\\israel-public-transportation_12072017_BSOnly\\stops1.txt", sep = ",", row.names = FALSE)
calender <- GTFScalender[GTFScalender$service_id %in% trips$service_id,]
write.table(calender,"C:\\Analysis\\GIS\\gtfs_data\\israel-public-transportation_12072017_BSOnly\\calender.txt", sep = ",", row.names = FALSE)
routes <- GTFSroutes[GTFSroutes$agency_id == 32,]
write.table(routes,"C:\\Analysis\\GIS\\gtfs_data\\israel-public-transportation_12072017_BSOnly\\routes.txt", sep = ",", row.names = FALSE)
trips <- GTFStrips[GTFStrips$route_id %in% routes$route_id,]
write.table(trips,"C:\\Analysis\\GIS\\gtfs_data\\israel-public-transportation_12072017_BSOnly\\trips.txt", sep = ",", row.names = FALSE)
shapes <- GTFSshapes[GTFSshapes$shape_id %in% trips$shape_id,]
write.table(shapes,"C:\\Analysis\\GIS\\gtfs_data\\israel-public-transportation_12072017_BSOnly\\shapes.txt", sep = ",", row.names = FALSE)
#All
stop_times <- GTFSstop_times[GTFSstop_times$trip_id %in% trips$trip_id,]
write.table(stop_times,"C:\\Analysis\\GIS\\gtfs_data\\israel-public-transportation_12072017_BSOnly\\stop_times.txt", sep = ",", row.names = FALSE)
stops <- GTFSstops[GTFSstops$stop_id %in% stop_times$stop_id,]
write.table(stops,"C:\\Analysis\\GIS\\gtfs_data\\israel-public-transportation_12072017_BSOnly\\stops1.txt", sep = ",", row.names = FALSE)
calender <- GTFScalender[GTFScalender$service_id %in% trips$service_id,]
calendar <- GTFScalendar[GTFScalendar$service_id %in% trips$service_id,]
write.table(calendar,"C:\\Analysis\\GIS\\gtfs_data\\israel-public-transportation_12072017_BSOnly\\calendar.txt", sep = ",", row.names = FALSE)
routes <- GTFSroutes[GTFSroutes$agency_id == 32,]
write.table(routes,"C:\\Analysis\\GIS\\gtfs_data\\israel-public-transportation_12072017_BSOnly\\routes.txt", sep = ",", row.names = FALSE)
head(routes)
rm
rm(ls)
rm(ls())
rm(ls(all()))
SubsetSIRI <- function(SIRIdf, lineref){
subdf <- SIRIdf[SIRIdf$LineRef == lineref,]
subdf
}
routes <- GTFSroutes[GTFSroutes$agency_id == 32,]
write.table(routes,"C:\\Analysis\\GIS\\gtfs_data\\israel-public-transportation_12072017_BSOnly\\routes.txt", sep = ",", row.names = FALSE)
loadGTFS()
SIRIdf <- read.csv(file = file.choose())
View(SIRIdf)
loadGTFS()
downloadGTFSil <- function(directory){
directory <- choose.dir()
date <- Sys.Date()
date <- as.character(as.POSIXct(strptime(date, format = "%Y-%m-%d")))
file_name <- as.character(paste("GTFS",date,".zip", sep = ""))
download.file("ftp://gtfs.mot.gov.il/israel-public-transportation.zip", destfile = paste0(directory,file_name), method = "libcurl")}
loadGTFS()
loadGTFS <- function(directory){
directory <- choose.dir()
origwd <- getwd()
setwd(directory)
temp = list.files(pattern="*.txt")
list2env(
lapply(setNames(temp, make.names(paste0("GTFS",gsub("*.txt$", "", temp)))),
read.csv,stringsAsFactors = FALSE, encoding = 'UTF-8', header = TRUE, quote = ""), envir = .GlobalEnv)
GTFSagency$agency_nameENG[GTFSagency$agency_id == 2] <- "Rail"
GTFSagency$agency_nameENG[GTFSagency$agency_id == 3] <- "Egged"
GTFSagency$agency_nameENG[GTFSagency$agency_id == 4] <- "Egged_Taavura"
GTFSagency$agency_nameENG[GTFSagency$agency_id == 5] <- "Dan"
GTFSagency$agency_nameENG[GTFSagency$agency_id == 6] <- "Nazareth-unbs"
GTFSagency$agency_nameENG[GTFSagency$agency_id == 7] <- "NTT"
GTFSagency$agency_nameENG[GTFSagency$agency_id == 8] <- "GB-Tours"
GTFSagency$agency_nameENG[GTFSagency$agency_id == 10] <- "Mo'atza Ezorit Eilot"
GTFSagency$agency_nameENG[GTFSagency$agency_id == 14] <- "Netiv Expres"
GTFSagency$agency_nameENG[GTFSagency$agency_id == 15] <- "Metropoline"
GTFSagency$agency_nameENG[GTFSagency$agency_id == 16] <- "Superbus"
GTFSagency$agency_nameENG[GTFSagency$agency_id == 18] <- "Kavim"
GTFSagency$agency_nameENG[GTFSagency$agency_id == 19] <- "Metrodan"
GTFSagency$agency_nameENG[GTFSagency$agency_id == 20] <- "Karmelit"
GTFSagency$agency_nameENG[GTFSagency$agency_id == 21] <- "CityPass"
GTFSagency$agency_nameENG[GTFSagency$agency_id == 23] <- "Galim"
GTFSagency$agency_nameENG[GTFSagency$agency_id == 24] <- "Mo'atza Ezorit Golan"
GTFSagency$agency_nameENG[GTFSagency$agency_id == 25] <- "Afikim"
GTFSagency$agency_nameENG[GTFSagency$agency_id == 30] <- "Dan Tzafon"
GTFSagency$agency_nameENG[GTFSagency$agency_id == 31] <- "Dan BaDarom"
GTFSagency$agency_nameENG[GTFSagency$agency_id == 32] <- "Dan Be'er Sheva"
GTFSagency$agency_nameENG[GTFSagency$agency_id == 42] <- "Jerusalem-Ramllah Ihud"
GTFSagency$agency_nameENG[GTFSagency$agency_id == 44] <- "Jerusalem-AbuTur-Anta Ihud"
GTFSagency$agency_nameENG[GTFSagency$agency_id == 45] <- "Jerusalem-Alawast Ihud"
GTFSagency$agency_nameENG[GTFSagency$agency_id == 47] <- "Jerusalem-Har Hazeitim"
GTFSagency$agency_nameENG[GTFSagency$agency_id == 49] <- "Jerusalem-Issawia'a-Shuaafat Ihud"
GTFSagency$agency_nameENG[GTFSagency$agency_id == 50] <- "Jerusalem Darom Ihud"
GTFSagency$agency_nameENG[GTFSagency$agency_id == 51] <- "Jerusalem Tzur Baer Ihud"
setwd(origwd)
}
loadGTFS()
GTFSroutes[GTFSroutes$agency_id == 32,]
loadGTFS <- function(directory){
directory <- choose.dir()
origwd <- getwd()
setwd(directory)
temp = list.files(pattern="*.txt")
list2env(
lapply(setNames(temp, make.names(paste0("GTFS",gsub("*.txt$", "", temp)))),
read.csv,stringsAsFactors = FALSE, header = TRUE, quote = ""), envir = .GlobalEnv)
GTFSagency$agency_nameENG[GTFSagency$agency_id == 2] <- "Rail"
GTFSagency$agency_nameENG[GTFSagency$agency_id == 3] <- "Egged"
GTFSagency$agency_nameENG[GTFSagency$agency_id == 4] <- "Egged_Taavura"
GTFSagency$agency_nameENG[GTFSagency$agency_id == 5] <- "Dan"
GTFSagency$agency_nameENG[GTFSagency$agency_id == 6] <- "Nazareth-unbs"
GTFSagency$agency_nameENG[GTFSagency$agency_id == 7] <- "NTT"
GTFSagency$agency_nameENG[GTFSagency$agency_id == 8] <- "GB-Tours"
GTFSagency$agency_nameENG[GTFSagency$agency_id == 10] <- "Mo'atza Ezorit Eilot"
GTFSagency$agency_nameENG[GTFSagency$agency_id == 14] <- "Netiv Expres"
GTFSagency$agency_nameENG[GTFSagency$agency_id == 15] <- "Metropoline"
GTFSagency$agency_nameENG[GTFSagency$agency_id == 16] <- "Superbus"
GTFSagency$agency_nameENG[GTFSagency$agency_id == 18] <- "Kavim"
GTFSagency$agency_nameENG[GTFSagency$agency_id == 19] <- "Metrodan"
GTFSagency$agency_nameENG[GTFSagency$agency_id == 20] <- "Karmelit"
GTFSagency$agency_nameENG[GTFSagency$agency_id == 21] <- "CityPass"
GTFSagency$agency_nameENG[GTFSagency$agency_id == 23] <- "Galim"
GTFSagency$agency_nameENG[GTFSagency$agency_id == 24] <- "Mo'atza Ezorit Golan"
GTFSagency$agency_nameENG[GTFSagency$agency_id == 25] <- "Afikim"
GTFSagency$agency_nameENG[GTFSagency$agency_id == 30] <- "Dan Tzafon"
GTFSagency$agency_nameENG[GTFSagency$agency_id == 31] <- "Dan BaDarom"
GTFSagency$agency_nameENG[GTFSagency$agency_id == 32] <- "Dan Be'er Sheva"
GTFSagency$agency_nameENG[GTFSagency$agency_id == 42] <- "Jerusalem-Ramllah Ihud"
GTFSagency$agency_nameENG[GTFSagency$agency_id == 44] <- "Jerusalem-AbuTur-Anta Ihud"
GTFSagency$agency_nameENG[GTFSagency$agency_id == 45] <- "Jerusalem-Alawast Ihud"
GTFSagency$agency_nameENG[GTFSagency$agency_id == 47] <- "Jerusalem-Har Hazeitim"
GTFSagency$agency_nameENG[GTFSagency$agency_id == 49] <- "Jerusalem-Issawia'a-Shuaafat Ihud"
GTFSagency$agency_nameENG[GTFSagency$agency_id == 50] <- "Jerusalem Darom Ihud"
GTFSagency$agency_nameENG[GTFSagency$agency_id == 51] <- "Jerusalem Tzur Baer Ihud"
setwd(origwd)
}
########################
# for this next function you'll need the GTFS files and an organized SIRI data frame, if the GTFS tables were lodad with loadGTFS() then the only thing neede to be defined is the SIRI data frame
#########   use StopsForSIRI instead  #####################
Stops4SIRI <- function(SIRI, stops = GTFSstops, routes = GTFSroutes, trips = GTFStrips, stoptimes = GTFSstop_times ){
SIRIroutes <- routes[routes$agency_id %in% SIRI$OperatorRef & routes$route_short_name %in% SIRI$PublishedLineName & routes$route_type %in% SIRI$DirectionRef,]
SIRItrips <- trips[trips$route_id %in% SIRIroutes$route_id,]
SIRIstop_times <- stoptimes[stoptimes$trip_id %in% SIRItrips$trip_id,]
SIRIstops <- stops[GTFSstops$stop_id %in% SIRIstop_times$stop_id,]
}
loadGTFS()
GTFSroutes[GTFSroutes$agency_id == 32,]
routes <- GTFSroutes[GTFSroutes$agency_id == 32,]
write.table(routes,"C:\\Analysis\\GIS\\gtfs_data\\israel-public-transportation_12072017_BSOnly\\routes.txt", sep = ",", row.names = FALSE)
trips <- GTFStrips[GTFStrips$route_id %in% routes$route_id,]
write.table(trips,"C:\\Analysis\\GIS\\gtfs_data\\israel-public-transportation_12072017_BSOnly\\trips.txt", sep = ",", row.names = FALSE)
shapes <- GTFSshapes[GTFSshapes$shape_id %in% trips$shape_id,]
write.table(shapes,"C:\\Analysis\\GIS\\gtfs_data\\israel-public-transportation_12072017_BSOnly\\shapes.txt", sep = ",", row.names = FALSE)
stop_times <- GTFSstop_times[GTFSstop_times$trip_id %in% trips$trip_id,]
write.table(stop_times,"C:\\Analysis\\GIS\\gtfs_data\\israel-public-transportation_12072017_BSOnly\\stop_times.txt", sep = ",", row.names = FALSE)
stops <- GTFSstops[GTFSstops$stop_id %in% stop_times$stop_id,]
write.table(stops,"C:\\Analysis\\GIS\\gtfs_data\\israel-public-transportation_12072017_BSOnly\\stops1.txt", sep = ",", row.names = FALSE)
calendar <- GTFScalendar[GTFScalendar$service_id %in% trips$service_id,]
write.table(calendar,"C:\\Analysis\\GIS\\gtfs_data\\israel-public-transportation_12072017_BSOnly\\calendar.txt", sep = ",", row.names = FALSE)
stops <- GTFSstops[GTFSstops$stop_id %in% stop_times$stop_id,]
write.table(stops,"C:\\Analysis\\GIS\\gtfs_data\\israel-public-transportation_12072017_BSOnly\\stops.txt", sep = ",", row.names = FALSE)
setwd("D:\\Data_for_model")
ls()
ls()
files = list.files(path = "./output/", pattern = "\\.shp$", full.names = TRUE)
files
10*200
11*200
library(sf)
install.packages("sf")
shiny::runApp('C:/Accessibility/dbscan/dbscan_app_b7_data')
runApp('C:/Accessibility/dbscan/dbscan_app_b7_data')
pnt = dat
pnt = dat
dat = spTransform(dat, "+proj=utm +zone=36 +datum=WGS84 +units=m +no_defs +ellps=WGS84 +towgs84=0,0,0")
library(magrittr)
library(shiny)
library(leaflet)
library(sp)
library(rgeos)
library(dbscan)
library(factoextra)
library(fpc)
dat = read.csv("origin_times_wgs84.csv", stringsAsFactors = FALSE) # Read CSV
setwd("C:/Accessibility/dbscan/dbscan_app_b7_data")
dat = read.csv("origin_times_wgs84.csv", stringsAsFactors = FALSE) # Read CSV
dupl = duplicated(dat[, c("lon", "lat")]) #
dat = dat[!dupl, ]
coordinates(dat) = ~ lon + lat
proj4string(dat) = "+proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0"
box = bbox(dat)
dat = spTransform(dat, "+proj=utm +zone=36 +datum=WGS84 +units=m +no_defs +ellps=WGS84 +towgs84=0,0,0")
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
library(magrittr)
library(shiny)
library(leaflet)
library(sp)
library(rgeos)
library(dbscan)
library(factoextra)
library(fpc)
install.packages("shiny")
install.packages("shiny")
library(shiny)
library(leaflet)
library(sp)
library(rgeos)
library(dbscan)
library(factoextra)
library(fpc)
dat = read.csv("origin_times_wgs84.csv", stringsAsFactors = FALSE) # Read CSV
library(fpc)
setwd("C:/Accessibility/dbscan/dbscan_app_b7_data")
runApp()
install.packages("shiny")
shiny::runApp()
runApp()
runApp()
runApp()
runApp()
?dbscan
#install.packages("fpc")
#install.packages("dbscan")
library(factoextra)
library(fpc)
data("multishapes", package = "factoextra")
df <- multishapes[, 1:2]
df
set.seed(123)
db <- fpc::dbscan(df, eps = 0.15, MinPts = 5)
fviz_cluster(db, data = df, stand = FALSE,
ellipse = FALSE, show.clust.cent = FALSE,
geom = "point",palette = "jco", ggtheme = theme_classic())
dbscan::kNNdistplot(df, k =  5)
abline(h = 0.15, lty = 2)
dbscan::kNNdistplot(df, k =  5)
abline(h = 0.15, lty = 2)
fviz_cluster(db, data = df, stand = FALSE,
ellipse = FALSE, show.clust.cent = FALSE,
geom = "point",palette = "jco", ggtheme = theme_classic())
db <- fpc::dbscan(df, eps = 0.1, MinPts = 5)
fviz_cluster(db, data = df, stand = FALSE,
ellipse = FALSE, show.clust.cent = FALSE,
geom = "point",palette = "jco", ggtheme = theme_classic())
runApp('C:/Accessibility/dbscan/dbscan_app_sintetic')
dat = read.csv("origin_times_wgs84.csv", stringsAsFactors = FALSE) # Read CSV
setwd("C:/Accessibility/dbscan/dbscan_app_sintetic")
dat = read.csv("origin_times_wgs84.csv", stringsAsFactors = FALSE) # Read CSV
runApp()
dupl = duplicated(dat[, c("lon", "lat")]) #
dat = read.csv("origin_times_wgs84.csv", stringsAsFactors = FALSE) # Read CSV
runApp('C:/Accessibility/dbscan/dbscan_app_b7_data')
runApp()
runApp()
runApp()
runApp()
dat = read.csv("origin_times_wgs84.csv", stringsAsFactors = FALSE) # Read CSV
dupl = duplicated(dat[, c("lon", "lat")]) #
dat = dat[!dupl, ]
coordinates(dat) = ~ lon + lat
proj4string(dat) = "+proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0"
box = bbox(dat)
dat = spTransform(dat, "+proj=utm +zone=36 +datum=WGS84 +units=m +no_defs +ellps=WGS84 +towgs84=0,0,0")
ui = bootstrapPage(
tags$style(type = "text/css", "html, body {width:100%;height:100%}"),
leafletOutput("map", width = "100%", height = "100%"),
absolutePanel(top = 10, right = 10,
sliderInput(
"eps", "Epsilon",
min = 10, max = 1000, value = 10, step = 10
),
sliderInput(
"minPts", "Min. Points",
min = 5, max = 100, value = 5, step = 5
)
)
)
server = function(input, output, session) {
pnt = reactive({
pnt = dat
res = dbscan::dbscan(cbind(coordinates(pnt), pnt$mean * 166.6667), eps = input$eps, minPts = input$minPts)
pnt$clus = res$cluster
pnt$clus[pnt$clus == 0] = NA
pnt
})
ch = reactive({
pnt_l = split(pnt(), pnt()$clus)
point_count = sapply(pnt_l, nrow)
pnt_l = pnt_l[point_count >= input$minPts]
ch = lapply(pnt_l, gConvexHull)
ch$makeUniqueIDs = TRUE
ch = do.call(rbind, ch)
ch = SpatialPolygonsDataFrame(
ch,
data.frame(clus = pnt_l %>% names %>% as.numeric),
match.ID = FALSE
)
ch$count = sapply(pnt_l, nrow)
ch
})
pal_rand = reactive({
pal = colorFactor("Spectral", pnt()$clus)
clus_range = range(pnt()$clus, na.rm = TRUE)
random_colors =
seq(clus_range[1], clus_range[2]) %>%
pal %>%
sample
colorFactor(random_colors, pnt()$clus)
})
output$map = renderLeaflet({
leaflet() %>%
addTiles %>%
fitBounds(box[1,1], box[2,1], box[1,2], box[2,2])
})
observe({
pnt() %>% spTransform("+proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0") %>% print
leafletProxy("map") %>%
clearMarkers %>%
clearShapes %>%
addCircleMarkers(
data = pnt() %>% spTransform("+proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0"),
group = "Points",
color = ~pal_rand()(clus)
) %>%
addPolygons(
data = ch() %>% spTransform("+proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0"),
group = "Polygons",
color = "black", dashArray = c(5, 5), opacity = 1, weight = 2,
popup = ~as.character(count),
fillColor = ~pal_rand()(clus)
) %>%
addLayersControl(
position = "bottomright",
overlayGroups = c("Points", "Polygons"),
options = layersControlOptions(collapsed = FALSE)
)
})
}
shinyApp(ui, server)
pnt = dat
res = dbscan::dbscan(cbind(coordinates(pnt), pnt$mean * 166.6667), eps = input$eps, minPts = input$minPts)
runApp()
#res = dbscan::dbscan(cbind(coordinates(pnt), pnt$mean * 166.6667), eps = input$eps, minPts = input$minPts)
res = dbscan::dbscan(cbind(coordinates(pnt), pnt$mean * 166.6667), eps = 5, minPts = 5)
plot(res)
plot(res, dat)
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
dat = read.csv("sint_times_wgs84.csv", stringsAsFactors = FALSE) # Read CSV
runApp()
runApp()
