s3 <- cbind(s2, depart_firststr)
s3$depart_firststr <- as.character(s3$depart_firststr)
s3$depart_first <- StopTimes2POSIXct(s3$depart_firststr,SIRIdf3)
s3$key <- paste(s3$depart_first," ", s3$stop_id)
s3$arrival_time <- StopTimes2POSIXct(s3$arrival_time,SIRIdf3)
s3$departure_time <- StopTimes2POSIXct(s3$departure_time,SIRIdf3)
s3 <- s3[!is.na(s3$arrival_time),]
s3
}else{
print('failed to subset stop times')
}
}
###########
# process the stop times df in order to use the times in it
#  warning, reqires 64 bit machine and 64 bit version of R.
# not recommended for use on the full df of GTFSstop_times
StopTimes2POSIXct <- function(column, SIRIref){
d <- column
time <- as.character(d)
date <- rep_len(as.character(as.Date(as.POSIXct(SIRIref$RecordedAtTime[1]))),length(time))
X <- paste(as.character(date)," ", as.character(time))
Y <- as.POSIXct(strptime(X,format = "%Y-%m-%d %H:%M:%S"))
Y
}
###############
# version of StopTimes2POSIXct for use in 32bit machines
# still might not work on entire GTFSstop_times
lowmemST2POSIX <- function(column, SIRIref){
s1 <- column
s2 <- as.Date(as.POSIXct(SIRIref$RecordedAtTime[1:length(column)]))
s2 <- as.character(s2)
s2 <- rep(s2[1],len = length(s1))
s3 <- s2[1:(length(s2)/2+1)]
s4 <- s2[length(s3):length(s2)]
s5 <- s1[1:(length(s1)/2+1)]
s6 <- s1[(length(s1)/2+1):length(s1)]
a1 <- paste0(s3, " ", s5)
a2 <- paste0(s4, " ", s6)
a3 <- (rbind(a1,a2))
a3 <- a3[1:(length(a3)-1)]
Y <- as.POSIXct(strptime(a3,format = "%Y-%m-%d %H:%M:%S"))
column <- Y
column <- column[-length(column)]
}
###############
# adding a trip number for the day
# will be used later for indexing
addtripnum <- function(ans2){
tripnum <- 1
tripnumvec <- vector()
ans2 <- ans2[order(ans2$OriginAimedDepartureTime,ans2$stop_sequence),]
ans2 <- ans2[!is.na(ans2$OriginAimedDepartureTime),]
for(ora in unique(ans2$OriginAimedDepartureTime[!is.na(ans2$OriginAimedDepartureTime)])){
if(length(ans2$OriginAimedDepartureTime[ans2$OriginAimedDepartureTime[!is.na(ans2$OriginAimedDepartureTime)] == ora]) > 0 ){
tripnumvec <-c(tripnumvec, rep_len(tripnum,length.out = length(ans2$OriginAimedDepartureTime[ans2$OriginAimedDepartureTime[!is.na(ans2$OriginAimedDepartureTime)] == ora]))  )
tripnum <- tripnum+1
}else{
tripnum <- tripnum+1
}
}
tripnumvec <- tripnumvec
ans2 <- cbind(ans2,tripnumvec)
}
loadcsv_multi <- function(directory){
directory <- choose.dir()
setwd(directory)
temp = list.files(pattern="*.csv")
list2env(
lapply(setNames(temp, make.names(paste0(gsub("*.csv$", "", temp)))),
read.csv,stringsAsFactors = FALSE, header = TRUE, quote = ""), envir = .GlobalEnv)
}
is.outlier <- function(spSIRI, trip){
siridfch <- gConvexHull(spSIRI[spSIRI@data$trip_id == trip,])
if(!is.null(siridfch)){
cent1 <- gCentroid(siridfch)
centbuffer <- gBuffer(cent1, width = 75)
outlier <- gWithin(spSIRI, centbuffer)
return(outlier)
}else{
print(paste('failed trip: ', trip))
}
}
loadGTFS()
trips <- GTFStrips[GTFStrips$route_id %in% routes$route_id,]
write.table(trips,"C:\\Analysis\\GIS\\gtfs_data\\israel-public-transportation_12072017_BSOnly\\trips.txt", sep = ",", row.names = FALSE)
shapes <- GTFSshapes[GTFSshapes$shape_id %in% trips$shape_id,]
write.table(shapes,"C:\\Analysis\\GIS\\gtfs_data\\israel-public-transportation_12072017_BSOnly\\shapes.txt", sep = ",", row.names = FALSE)
#All
stop_times <- GTFSstop_times[GTFSstop_times$trip_id %in% trips$trip_id,]
write.table(stop_times,"C:\\Analysis\\GIS\\gtfs_data\\israel-public-transportation_12072017_BSOnly\\stop_times.txt", sep = ",", row.names = FALSE)
stops <- GTFSstops[GTFSstops$stop_id %in% stop_times$stop_id,]
write.table(stops,"C:\\Analysis\\GIS\\gtfs_data\\israel-public-transportation_12072017_BSOnly\\stops1.txt", sep = ",", row.names = FALSE)
calender <- GTFScalender[GTFScalender$service_id %in% trips$service_id,]
write.table(calender,"C:\\Analysis\\GIS\\gtfs_data\\israel-public-transportation_12072017_BSOnly\\calender.txt", sep = ",", row.names = FALSE)
routes <- GTFSroutes[GTFSroutes$agency_id == 32,]
write.table(routes,"C:\\Analysis\\GIS\\gtfs_data\\israel-public-transportation_12072017_BSOnly\\routes.txt", sep = ",", row.names = FALSE)
trips <- GTFStrips[GTFStrips$route_id %in% routes$route_id,]
write.table(trips,"C:\\Analysis\\GIS\\gtfs_data\\israel-public-transportation_12072017_BSOnly\\trips.txt", sep = ",", row.names = FALSE)
shapes <- GTFSshapes[GTFSshapes$shape_id %in% trips$shape_id,]
write.table(shapes,"C:\\Analysis\\GIS\\gtfs_data\\israel-public-transportation_12072017_BSOnly\\shapes.txt", sep = ",", row.names = FALSE)
#All
stop_times <- GTFSstop_times[GTFSstop_times$trip_id %in% trips$trip_id,]
write.table(stop_times,"C:\\Analysis\\GIS\\gtfs_data\\israel-public-transportation_12072017_BSOnly\\stop_times.txt", sep = ",", row.names = FALSE)
stops <- GTFSstops[GTFSstops$stop_id %in% stop_times$stop_id,]
write.table(stops,"C:\\Analysis\\GIS\\gtfs_data\\israel-public-transportation_12072017_BSOnly\\stops1.txt", sep = ",", row.names = FALSE)
calender <- GTFScalender[GTFScalender$service_id %in% trips$service_id,]
calendar <- GTFScalendar[GTFScalendar$service_id %in% trips$service_id,]
write.table(calendar,"C:\\Analysis\\GIS\\gtfs_data\\israel-public-transportation_12072017_BSOnly\\calendar.txt", sep = ",", row.names = FALSE)
routes <- GTFSroutes[GTFSroutes$agency_id == 32,]
write.table(routes,"C:\\Analysis\\GIS\\gtfs_data\\israel-public-transportation_12072017_BSOnly\\routes.txt", sep = ",", row.names = FALSE)
head(routes)
rm
rm(ls)
rm(ls())
rm(ls(all()))
SubsetSIRI <- function(SIRIdf, lineref){
subdf <- SIRIdf[SIRIdf$LineRef == lineref,]
subdf
}
routes <- GTFSroutes[GTFSroutes$agency_id == 32,]
write.table(routes,"C:\\Analysis\\GIS\\gtfs_data\\israel-public-transportation_12072017_BSOnly\\routes.txt", sep = ",", row.names = FALSE)
loadGTFS()
SIRIdf <- read.csv(file = file.choose())
View(SIRIdf)
loadGTFS()
downloadGTFSil <- function(directory){
directory <- choose.dir()
date <- Sys.Date()
date <- as.character(as.POSIXct(strptime(date, format = "%Y-%m-%d")))
file_name <- as.character(paste("GTFS",date,".zip", sep = ""))
download.file("ftp://gtfs.mot.gov.il/israel-public-transportation.zip", destfile = paste0(directory,file_name), method = "libcurl")}
loadGTFS()
loadGTFS <- function(directory){
directory <- choose.dir()
origwd <- getwd()
setwd(directory)
temp = list.files(pattern="*.txt")
list2env(
lapply(setNames(temp, make.names(paste0("GTFS",gsub("*.txt$", "", temp)))),
read.csv,stringsAsFactors = FALSE, encoding = 'UTF-8', header = TRUE, quote = ""), envir = .GlobalEnv)
GTFSagency$agency_nameENG[GTFSagency$agency_id == 2] <- "Rail"
GTFSagency$agency_nameENG[GTFSagency$agency_id == 3] <- "Egged"
GTFSagency$agency_nameENG[GTFSagency$agency_id == 4] <- "Egged_Taavura"
GTFSagency$agency_nameENG[GTFSagency$agency_id == 5] <- "Dan"
GTFSagency$agency_nameENG[GTFSagency$agency_id == 6] <- "Nazareth-unbs"
GTFSagency$agency_nameENG[GTFSagency$agency_id == 7] <- "NTT"
GTFSagency$agency_nameENG[GTFSagency$agency_id == 8] <- "GB-Tours"
GTFSagency$agency_nameENG[GTFSagency$agency_id == 10] <- "Mo'atza Ezorit Eilot"
GTFSagency$agency_nameENG[GTFSagency$agency_id == 14] <- "Netiv Expres"
GTFSagency$agency_nameENG[GTFSagency$agency_id == 15] <- "Metropoline"
GTFSagency$agency_nameENG[GTFSagency$agency_id == 16] <- "Superbus"
GTFSagency$agency_nameENG[GTFSagency$agency_id == 18] <- "Kavim"
GTFSagency$agency_nameENG[GTFSagency$agency_id == 19] <- "Metrodan"
GTFSagency$agency_nameENG[GTFSagency$agency_id == 20] <- "Karmelit"
GTFSagency$agency_nameENG[GTFSagency$agency_id == 21] <- "CityPass"
GTFSagency$agency_nameENG[GTFSagency$agency_id == 23] <- "Galim"
GTFSagency$agency_nameENG[GTFSagency$agency_id == 24] <- "Mo'atza Ezorit Golan"
GTFSagency$agency_nameENG[GTFSagency$agency_id == 25] <- "Afikim"
GTFSagency$agency_nameENG[GTFSagency$agency_id == 30] <- "Dan Tzafon"
GTFSagency$agency_nameENG[GTFSagency$agency_id == 31] <- "Dan BaDarom"
GTFSagency$agency_nameENG[GTFSagency$agency_id == 32] <- "Dan Be'er Sheva"
GTFSagency$agency_nameENG[GTFSagency$agency_id == 42] <- "Jerusalem-Ramllah Ihud"
GTFSagency$agency_nameENG[GTFSagency$agency_id == 44] <- "Jerusalem-AbuTur-Anta Ihud"
GTFSagency$agency_nameENG[GTFSagency$agency_id == 45] <- "Jerusalem-Alawast Ihud"
GTFSagency$agency_nameENG[GTFSagency$agency_id == 47] <- "Jerusalem-Har Hazeitim"
GTFSagency$agency_nameENG[GTFSagency$agency_id == 49] <- "Jerusalem-Issawia'a-Shuaafat Ihud"
GTFSagency$agency_nameENG[GTFSagency$agency_id == 50] <- "Jerusalem Darom Ihud"
GTFSagency$agency_nameENG[GTFSagency$agency_id == 51] <- "Jerusalem Tzur Baer Ihud"
setwd(origwd)
}
loadGTFS()
GTFSroutes[GTFSroutes$agency_id == 32,]
loadGTFS <- function(directory){
directory <- choose.dir()
origwd <- getwd()
setwd(directory)
temp = list.files(pattern="*.txt")
list2env(
lapply(setNames(temp, make.names(paste0("GTFS",gsub("*.txt$", "", temp)))),
read.csv,stringsAsFactors = FALSE, header = TRUE, quote = ""), envir = .GlobalEnv)
GTFSagency$agency_nameENG[GTFSagency$agency_id == 2] <- "Rail"
GTFSagency$agency_nameENG[GTFSagency$agency_id == 3] <- "Egged"
GTFSagency$agency_nameENG[GTFSagency$agency_id == 4] <- "Egged_Taavura"
GTFSagency$agency_nameENG[GTFSagency$agency_id == 5] <- "Dan"
GTFSagency$agency_nameENG[GTFSagency$agency_id == 6] <- "Nazareth-unbs"
GTFSagency$agency_nameENG[GTFSagency$agency_id == 7] <- "NTT"
GTFSagency$agency_nameENG[GTFSagency$agency_id == 8] <- "GB-Tours"
GTFSagency$agency_nameENG[GTFSagency$agency_id == 10] <- "Mo'atza Ezorit Eilot"
GTFSagency$agency_nameENG[GTFSagency$agency_id == 14] <- "Netiv Expres"
GTFSagency$agency_nameENG[GTFSagency$agency_id == 15] <- "Metropoline"
GTFSagency$agency_nameENG[GTFSagency$agency_id == 16] <- "Superbus"
GTFSagency$agency_nameENG[GTFSagency$agency_id == 18] <- "Kavim"
GTFSagency$agency_nameENG[GTFSagency$agency_id == 19] <- "Metrodan"
GTFSagency$agency_nameENG[GTFSagency$agency_id == 20] <- "Karmelit"
GTFSagency$agency_nameENG[GTFSagency$agency_id == 21] <- "CityPass"
GTFSagency$agency_nameENG[GTFSagency$agency_id == 23] <- "Galim"
GTFSagency$agency_nameENG[GTFSagency$agency_id == 24] <- "Mo'atza Ezorit Golan"
GTFSagency$agency_nameENG[GTFSagency$agency_id == 25] <- "Afikim"
GTFSagency$agency_nameENG[GTFSagency$agency_id == 30] <- "Dan Tzafon"
GTFSagency$agency_nameENG[GTFSagency$agency_id == 31] <- "Dan BaDarom"
GTFSagency$agency_nameENG[GTFSagency$agency_id == 32] <- "Dan Be'er Sheva"
GTFSagency$agency_nameENG[GTFSagency$agency_id == 42] <- "Jerusalem-Ramllah Ihud"
GTFSagency$agency_nameENG[GTFSagency$agency_id == 44] <- "Jerusalem-AbuTur-Anta Ihud"
GTFSagency$agency_nameENG[GTFSagency$agency_id == 45] <- "Jerusalem-Alawast Ihud"
GTFSagency$agency_nameENG[GTFSagency$agency_id == 47] <- "Jerusalem-Har Hazeitim"
GTFSagency$agency_nameENG[GTFSagency$agency_id == 49] <- "Jerusalem-Issawia'a-Shuaafat Ihud"
GTFSagency$agency_nameENG[GTFSagency$agency_id == 50] <- "Jerusalem Darom Ihud"
GTFSagency$agency_nameENG[GTFSagency$agency_id == 51] <- "Jerusalem Tzur Baer Ihud"
setwd(origwd)
}
########################
# for this next function you'll need the GTFS files and an organized SIRI data frame, if the GTFS tables were lodad with loadGTFS() then the only thing neede to be defined is the SIRI data frame
#########   use StopsForSIRI instead  #####################
Stops4SIRI <- function(SIRI, stops = GTFSstops, routes = GTFSroutes, trips = GTFStrips, stoptimes = GTFSstop_times ){
SIRIroutes <- routes[routes$agency_id %in% SIRI$OperatorRef & routes$route_short_name %in% SIRI$PublishedLineName & routes$route_type %in% SIRI$DirectionRef,]
SIRItrips <- trips[trips$route_id %in% SIRIroutes$route_id,]
SIRIstop_times <- stoptimes[stoptimes$trip_id %in% SIRItrips$trip_id,]
SIRIstops <- stops[GTFSstops$stop_id %in% SIRIstop_times$stop_id,]
}
loadGTFS()
GTFSroutes[GTFSroutes$agency_id == 32,]
routes <- GTFSroutes[GTFSroutes$agency_id == 32,]
write.table(routes,"C:\\Analysis\\GIS\\gtfs_data\\israel-public-transportation_12072017_BSOnly\\routes.txt", sep = ",", row.names = FALSE)
trips <- GTFStrips[GTFStrips$route_id %in% routes$route_id,]
write.table(trips,"C:\\Analysis\\GIS\\gtfs_data\\israel-public-transportation_12072017_BSOnly\\trips.txt", sep = ",", row.names = FALSE)
shapes <- GTFSshapes[GTFSshapes$shape_id %in% trips$shape_id,]
write.table(shapes,"C:\\Analysis\\GIS\\gtfs_data\\israel-public-transportation_12072017_BSOnly\\shapes.txt", sep = ",", row.names = FALSE)
stop_times <- GTFSstop_times[GTFSstop_times$trip_id %in% trips$trip_id,]
write.table(stop_times,"C:\\Analysis\\GIS\\gtfs_data\\israel-public-transportation_12072017_BSOnly\\stop_times.txt", sep = ",", row.names = FALSE)
stops <- GTFSstops[GTFSstops$stop_id %in% stop_times$stop_id,]
write.table(stops,"C:\\Analysis\\GIS\\gtfs_data\\israel-public-transportation_12072017_BSOnly\\stops1.txt", sep = ",", row.names = FALSE)
calendar <- GTFScalendar[GTFScalendar$service_id %in% trips$service_id,]
write.table(calendar,"C:\\Analysis\\GIS\\gtfs_data\\israel-public-transportation_12072017_BSOnly\\calendar.txt", sep = ",", row.names = FALSE)
stops <- GTFSstops[GTFSstops$stop_id %in% stop_times$stop_id,]
write.table(stops,"C:\\Analysis\\GIS\\gtfs_data\\israel-public-transportation_12072017_BSOnly\\stops.txt", sep = ",", row.names = FALSE)
setwd("D:/Users/omrya/Dropbox/University2013-2016/Semester_10_2018/GIS_models/Exc/Exc2")
dat = read.csv("avatz_uncertainty_class2.csv")
dat
head(dat)
data = read.csv("avatz_uncertainty_class2.csv")
sample <- sample.int(n = nrow(data), size = floor(.75*nrow(data)), replace = F)
train <- data[sample, ]
test  <- data[-sample, ]
train
nrow(train)
nrow(data)
sample <- sample.int(n = nrow(data), size = floor(.5*nrow(data)), replace = F)
train <- data[sample, ]
test  <- data[-sample, ]
nrow(train)
nrow(data)
rmse(train$zinc_obs, train$zinc_pred)
install.packages("Metrics")
library(Matrics)
library("Matrics")
library("Metrics")
rmse(train$zinc_obs, train$zinc_pred)
rmse(test$zinc_obs, test$zinc_pred)
##Normalized##
AVG = rmse(train$zinc_obs, train$zinc_pred) / mean(train$zinc_obs)
AVG
AVG = rmse(test$zinc_obs, train$zinc_pred) / mean(test$zinc_obs)
##Normalized##
AVG = rmse(train$zinc_obs, train$zinc_pred) / mean(train$zinc_obs)
##Normalized##
AVG_train = rmse(train$zinc_obs, train$zinc_pred) / mean(train$zinc_obs)
AVG_test = rmse(test$zinc_obs, train$zinc_pred) / mean(test$zinc_obs)
AVG_train
AVG_test
AVG_test
range_train = rmse(train$zinc_obs, train$zinc_pred) / ((max(train$zinc_obs)- min(train$zinc_obs))
q
range_train = rmse(train$zinc_obs, train$zinc_pred) / (max(train$zinc_obs)- min(train$zinc_obs))
range_train
range_test = rmse(test$zinc_obs, test$zinc_pred) / (max(test$zinc_obs)- min(test$zinc_obs))
range_test
library(Hmisc)
install.packages("Hmisc")
library(Hmisc)
cor(train$zinc_obs, train$zinc_pred)
cor(train$zinc_obs, train$zinc_pred, type = "Pearson")
cor(train$zinc_obs, train$zinc_pred, type = "pearson")
cor(train$zinc_obs, train$zinc_pred, method = "pearson")
cor(train$zinc_obs, train$zinc_pred,  method = c("pearson", "kendall", "spearman")))
cor(train$zinc_obs, train$zinc_pred,  method = c("pearson", "kendall", "spearman"))
cor(train$zinc_obs, train$zinc_pred,  method = c("pearson")
q
cor(train$zinc_obs, train$zinc_pred,  method = c("pearson"))
cor(test$zinc_obs, test$zinc_pred,  method = c("pearson"))
install.packages("hydroGOF")
library("hydroGOF")
##NSE##
NSE(train$zinc_obs, train$zinc_pred)
NSE(test$zinc_obs, test$zinc_pred)
data = read.csv("avatz_uncertainty_class2.csv")
##Split data##
sample <- sample.int(n = nrow(data), size = floor(.5*nrow(data)), replace = F)
train <- data[sample, ]
test  <- data[-sample, ]
##Calculate RMSE##
rmse(train$zinc_obs, train$zinc_pred)
rmse(test$zinc_obs, test$zinc_pred)
##Normalized##
AVG_train = rmse(train$zinc_obs, train$zinc_pred) / mean(train$zinc_obs)
AVG_train
AVG_test = rmse(test$zinc_obs, train$zinc_pred) / mean(test$zinc_obs)
AVG_test
range_train = rmse(train$zinc_obs, train$zinc_pred) / (max(train$zinc_obs)- min(train$zinc_obs))
range_train
range_test = rmse(test$zinc_obs, test$zinc_pred) / (max(test$zinc_obs)- min(test$zinc_obs))
range_test
##Pearson##
cor(train$zinc_obs, train$zinc_pred,  method = c("pearson"))
cor(test$zinc_obs, test$zinc_pred,  method = c("pearson"))
##NSE##
NSE(train$zinc_obs, train$zinc_pred)
NSE(test$zinc_obs, test$zinc_pred)
clear
data = read.csv("avatz_uncertainty_class2.csv")
##Split data##
sample <- sample.int(n = nrow(data), size = floor(.5*nrow(data)), replace = F)
train <- data[sample, ]
test  <- data[-sample, ]
##Calculate RMSE##
rmse(train$zinc_obs, train$zinc_pred)
rmse(test$zinc_obs, test$zinc_pred)
##Normalized##
AVG_train = rmse(train$zinc_obs, train$zinc_pred) / mean(train$zinc_obs)
AVG_train
AVG_test = rmse(test$zinc_obs, train$zinc_pred) / mean(test$zinc_obs)
AVG_test
range_train = rmse(train$zinc_obs, train$zinc_pred) / (max(train$zinc_obs)- min(train$zinc_obs))
range_train
range_test = rmse(test$zinc_obs, test$zinc_pred) / (max(test$zinc_obs)- min(test$zinc_obs))
range_test
##Pearson##
cor(train$zinc_obs, train$zinc_pred,  method = c("pearson"))
cor(test$zinc_obs, test$zinc_pred,  method = c("pearson"))
##NSE##
NSE(train$zinc_obs, train$zinc_pred)
NSE(test$zinc_obs, test$zinc_pred)
##Normalized##
AVG_train = rmse(train$zinc_obs, train$zinc_pred) / mean(train$zinc_obs)
AVG_train
AVG_test = rmse(test$zinc_obs, test$zinc_pred) / mean(test$zinc_obs)
AVG_test
##Split data##
sample <- sample.int(n = nrow(data), size = floor(.5*nrow(data)), replace = F)
train <- data[sample, ]
test  <- data[-sample, ]
##Calculate RMSE##
rmse(train$zinc_obs, train$zinc_pred)
rmse(test$zinc_obs, test$zinc_pred)
##Normalized##
AVG_train = rmse(train$zinc_obs, train$zinc_pred) / mean(train$zinc_obs)
AVG_train
AVG_test = rmse(test$zinc_obs, test$zinc_pred) / mean(test$zinc_obs)
AVG_test
range_train = rmse(train$zinc_obs, train$zinc_pred) / (max(train$zinc_obs)- min(train$zinc_obs))
range_train
range_test = rmse(test$zinc_obs, test$zinc_pred) / (max(test$zinc_obs)- min(test$zinc_obs))
range_test
##Pearson##
cor(train$zinc_obs, train$zinc_pred,  method = c("pearson"))
cor(test$zinc_obs, test$zinc_pred,  method = c("pearson"))
##NSE##
NSE(train$zinc_obs, train$zinc_pred)
NSE(test$zinc_obs, test$zinc_pred)
?sample.int
##Split data##
sample <- sample.int(n = nrow(data), size = floor(.25*nrow(data)), replace = F)
train <- data[sample, ]
test  <- data[-sample, ]
##Calculate RMSE##
rmse(train$zinc_obs, train$zinc_pred)
rmse(test$zinc_obs, test$zinc_pred)
##Normalized##
AVG_train = rmse(train$zinc_obs, train$zinc_pred) / mean(train$zinc_obs)
AVG_train
AVG_test = rmse(test$zinc_obs, test$zinc_pred) / mean(test$zinc_obs)
AVG_test
range_train = rmse(train$zinc_obs, train$zinc_pred) / (max(train$zinc_obs)- min(train$zinc_obs))
range_train
range_test = rmse(test$zinc_obs, test$zinc_pred) / (max(test$zinc_obs)- min(test$zinc_obs))
range_test
##Pearson##
cor(train$zinc_obs, train$zinc_pred,  method = c("pearson"))
cor(test$zinc_obs, test$zinc_pred,  method = c("pearson"))
##NSE##
NSE(train$zinc_obs, train$zinc_pred)
NSE(test$zinc_obs, test$zinc_pred)
data.frame()
matrix(, ncol = 3)
matrix(, ncol = 3, nrow = 3)
mat = matrix(, ncol = 3, nrow = 3)
mat [1] = c(25,33,70)
mat [1,] = c(25,33,70)
mat
mat [2,] = c(24,36,76)
mat = matrix(c(25,33,70) , ncol = 3, nrow = 3)
mat
mat = matrix(c(25,33,70, 61) , ncol = 3, nrow = 3)
mat = matrix(, ncol = 3, nrow = 3)
mat
mat [1,] = c(25,33,70)
mat [2,] = c(24,36,76)
mat [1,] = c(12,15,100)
mat
mat [1,] = c(25,33,70)
mat [2,] = c(24,36,76)
mat [3,] = c(12,15,100)
mat
mat_2 = matrix(, ncol = 3, nrow = 3)
mat_2 [1,] = c(9,17,24)
mat_2 [2,] = c(13,14,21)
mat_2 [3,] = c(6,9,18)
mat_2
library(raster)
install.packages("raster")
library(raster)
library(raster)
r = stack(mat_2,mat)
NSE(train$zinc_obs, train$zinc_pred)
NSE(test$zinc_obs, test$zinc_pred)
NSE(dat$zinc_obs, test$zinc_pred)
NSE(data$zinc_obs, test$zinc_pred)
NSE(data$zinc_obs, data$zinc_pred)
r = stack(mat_2,mat)
mat
mat_2
r = stack(mat_2,mat)
?stack
r = stack(mat_2,mat)
r = stack(mat_2,mat)
mat_multi = mat *mat_2
mat_mu
mat_multi
mat_usle = sqrt((mat*3/mat)^2 + (mat_2*6 / mat_2)^2)
mat_usle
shiny::runApp('D:/Users/omrya/Dropbox/University2013-2016/Semester_7_2017/WebAplication/Apps/flickr_dbscan')
library(shiny)
library(leaflet)
library(sp)
library(rgeos)
library(dbscan)
install.packages(dbscan)
install.packages("dbscan")
install.packages("dbscan")
library(dbscan)
runApp('D:/Users/omrya/Dropbox/University2013-2016/Semester_7_2017/WebAplication/Apps/flickr_dbscan')
library(leaflet)
install.packages("leaflet")
install.packages("sp")
install.packages("sp")
install.packages("rgeos")
library(shiny)
library(leaflet)
library(sp)
library(rgeos)
runApp('D:/Users/omrya/Dropbox/University2013-2016/Semester_7_2017/WebAplication/Apps/flickr_dbscan')
dat
head(dat)
dat = read.csv("flickr_boston.csv", stringsAsFactors = FALSE) # Read CSV
setwd("D:/Users/omrya/Dropbox/University2013-2016/MA_2016-18/Acceessibility Research/GIS/Apps/dbscan")
runApp('D:/Users/omrya/Dropbox/University2013-2016/Semester_7_2017/WebAplication/Apps/flickr_dbscan')
dat = read.csv("origin_time.csv", stringsAsFactors = FALSE) # Read CSV
runApp('D:/Users/omrya/Dropbox/University2013-2016/Semester_7_2017/WebAplication/Apps/flickr_dbscan')
dat = read.csv("origin_time.csv", stringsAsFactors = FALSE) # Read CSV
dupl = duplicated(dat[, c("lon", "lat")]) #
dupl = duplicated(dat[, c("x", "y")]) #
dupl = duplicated(dat[, c("X", "Y")]) #
dat = read.csv("origin_time.csv", stringsAsFactors = FALSE) # Read CSV
dupl = duplicated(dat[, c("lon", "lat")]) #
dat = dat[!dupl, ]
coordinates(dat) = ~ lon + lat
coordinates(dat) = ~ lon + lat
proj4string(dat) = "+proj=longlat +datum=WGS84"
library(sp)
library(rgeos)
library(dbscan)
dat = dat[!dupl, ]
coordinates(dat) = ~ lon + lat
proj4string(dat) = "+proj=longlat +datum=WGS84"
dupl = duplicated(dat[, c("lon", "lat")]) #
dat = dat[!dupl, ]
coordinates(dat) = ~ lon + lat
proj4string(dat) = "+proj=longlat +datum=WGS84"
proj4string(dat) = "+proj=merc +lon_0=0 +k=1 +x_0=0 +y_0=0 +a=6378137 +b=6378137 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs "
coordinates(dat) = ~ lon + lat
dat = read.csv("origin_times_wgs84.csv", stringsAsFactors = FALSE) # Read CSV
dupl = duplicated(dat[, c("lon", "lat")]) #
dat = dat[!dupl, ]
coordinates(dat) = ~ lon + lat
proj4string(dat) = "+proj=merc +lon_0=0 +k=1 +x_0=0 +y_0=0 +a=6378137 +b=6378137 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs "
box = bbox(dat)
?bbox
shiny::runApp()
runApp()
runApp('D:/Users/omrya/Dropbox/University2013-2016/MA_2016-18/Acceessibility Research/GIS/Apps/flickr_dbscan')
setwd("D:/Users/omrya/Dropbox/University2013-2016/MA_2016-18/Acceessibility Research/GIS/Apps/flickr_dbscan")
runApp()
dat = read.csv("flickr_boston.csv", stringsAsFactors = FALSE) # Read CSV
dupl = duplicated(dat[, c("lon", "lat")]) #
dat = dat[!dupl, ]
coordinates(dat) = ~ lon + lat
proj4string(dat) = "+proj=longlat +datum=WGS84"
runApp()
runApp('D:/Users/omrya/Dropbox/University2013-2016/MA_2016-18/Acceessibility Research/GIS/Apps/dbscan')
runApp('D:/Users/omrya/Dropbox/University2013-2016/MA_2016-18/Acceessibility Research/GIS/Apps/dbscan')
runApp('D:/Users/omrya/Dropbox/University2013-2016/MA_2016-18/Acceessibility Research/GIS/Apps/dbscan')
shiny::runApp()
shiny::runApp()
